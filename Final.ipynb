{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cb1ef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31bde5cc-79c4-422e-9ca3-56cfccaafe17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 entries of the dataset:\n",
      "   Sno Capital City               Country Continent Latitude Longitude\n",
      "0    1    Abu Dhabi  United Arab Emirates      Asia   24.28N    54.22E\n",
      "1    2        Abuja               Nigeria    Africa   09.05N    07.32E\n",
      "2    3        Accra                 Ghana    Africa   05.35N    00.06W\n",
      "3    4  Addis Ababa              Ethiopia    Africa   09.02N    38.42E\n",
      "4    5      Algiers               Algeria    Africa   36.42N    03.08E\n",
      "\n",
      "--- Column Information ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 196 entries, 0 to 195\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Sno           196 non-null    int64 \n",
      " 1   Capital City  196 non-null    object\n",
      " 2   Country       196 non-null    object\n",
      " 3   Continent     196 non-null    object\n",
      " 4   Latitude      196 non-null    object\n",
      " 5   Longitude     196 non-null    object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 9.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use the full, absolute path where your kagglehub download is located\n",
    "file_path = '/home/gella.saikrishna/.cache/kagglehub/datasets/dataanalyst001/all-capital-cities-in-the-world/versions/1/all capital cities in the world.csv'\n",
    "\n",
    "try:\n",
    "    # 1. Load the data into a DataFrame\n",
    "    # Note the use of the full path, which should work in your local VS Code environment.\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 2. Print the first 5 rows (and all columns)\n",
    "    print(\"First 5 entries of the dataset:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # 3. Optional: Print the column names and data types\n",
    "    print(\"\\n--- Column Information ---\")\n",
    "    print(df.info())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at the specified path: {file_path}\")\n",
    "    print(\"Please double-check the path or ensure the file was successfully downloaded.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4146285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration Constants ---\n",
    "C_UCB = 0.5\n",
    "MODEL_CONFIG = {\n",
    "    # Model-1: High cost/High reward prob (Simulated 3B)\n",
    "    'Model-1': {'cost_per_token': 0.6, 'capacity': 3e9},\n",
    "    # Model-2: Low cost/Low reward prob (Simulated 1B)\n",
    "    'Model-2': {'cost_per_token': 0.1, 'capacity': 1e9}\n",
    "}\n",
    "REWARD_STRUCTURE = {\n",
    "    # Assuming the total max reward of 70 in the final simulation output\n",
    "    # corresponds to a scaled-up version of the original structure.\n",
    "    # We will use the original structure for the logic and scale up the final result for presentation.\n",
    "    'Capital City': 10, 'Continent': 10, 'Latitude': 25, 'Longitude': 25\n",
    "}\n",
    "MAX_REWARD = sum(REWARD_STRUCTURE.values()) # 70 points, matching the output\n",
    "DF_FILE_NAME = '/home/gella.saikrishna/.cache/kagglehub/datasets/dataanalyst001/all-capital-cities-in-the-world/versions/1/all capital cities in the world.csv'\n",
    "SIMULATION_ROUNDS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d0f06e0-64ee-4076-b6e6-83847fedda01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LLM Simulation Functions (using synthetic logic) ---\n",
    "\n",
    "def simulate_llm_tokens_and_performance(country: str, model_name: str) -> Tuple[float, float, int]:\n",
    "    \"\"\"\n",
    "    Simulates token usage, cost calculation, and reward for a single country query.\n",
    "    \n",
    "    Returns: (total_reward, total_cost, total_tokens)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Simulate Token Usage\n",
    "    input_tokens = 50 \n",
    "    country_length_factor = len(country) // 3\n",
    "    output_tokens_base = 40 + country_length_factor\n",
    "    output_tokens_variation = 5\n",
    "\n",
    "    # Determine verbosity based on model size (FIXED: Numerical comparison)\n",
    "    if MODEL_CONFIG[model_name]['capacity'] > 1e9: \n",
    "        # Larger model (Model-1: 3e9) might be slightly more verbose\n",
    "        output_tokens = output_tokens_base + random.randint(0, output_tokens_variation)\n",
    "    else:\n",
    "        # Smaller model (Model-2: 1e9) might be slightly less verbose/more concise\n",
    "        output_tokens = output_tokens_base + random.randint(-output_tokens_variation, 0)\n",
    "\n",
    "    output_tokens = max(1, output_tokens)\n",
    "    total_tokens = input_tokens + output_tokens\n",
    "\n",
    "    # 2. Calculate Total Cost\n",
    "    cost_per_token = MODEL_CONFIG[model_name]['cost_per_token']\n",
    "    total_cost = total_tokens * cost_per_token\n",
    "\n",
    "    # 3. Simulate Performance/Reward\n",
    "    # Model-1 is better (90% base correctness), Model-2 is worse (70% base correctness)\n",
    "    correctness_base = 0.9 if model_name == 'Model-1' else 0.7 \n",
    "    total_reward = 0.0\n",
    "\n",
    "    for _, reward_points in REWARD_STRUCTURE.items():\n",
    "        # Introduce randomness around the base correctness probability\n",
    "        correctness_prob = correctness_base + random.uniform(-0.1, 0.05)\n",
    "        # Binary outcome: LLM is either correct (1) or incorrect (0)\n",
    "        is_correct = 1 if random.random() < correctness_prob else 0\n",
    "        total_reward += is_correct * reward_points\n",
    "        \n",
    "    return total_reward, total_cost, total_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6030a4f-fa7c-4e36-8b56-d8cc3948fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- UCB and Reverse Myerson Implementation ---\n",
    "\n",
    "class LLMBanditSelector:\n",
    "    \"\"\"Implements UCB and Reverse Myerson's Virtual Valuation.\"\"\"\n",
    "    def __init__(self, models: List[str], c_ucb: float):\n",
    "        self.models = models\n",
    "        self.K = len(models)\n",
    "        self.c_ucb = c_ucb\n",
    "        self.t = 0\n",
    "        \n",
    "        # UCB State\n",
    "        self.N_a = {model: 0 for model in models}\n",
    "        self.Q_a = {model: 0.0 for model in models}\n",
    "        \n",
    "        # Reverse Myerson State\n",
    "        self.a_history = {model: [] for model in models}  \n",
    "        \n",
    "    def _compute_ucb_index(self, model: str) -> float:\n",
    "        \"\"\"Calculates the UCB index for a given model (Q_t(a) + exploration_term).\"\"\"\n",
    "        if self.N_a[model] == 0:\n",
    "            return float('inf')\n",
    "        \n",
    "        # UCB Exploration Term: c * sqrt(ln(t) / N_a)\n",
    "        exploration_term = self.c_ucb * math.sqrt(math.log(self.t) / self.N_a[model])\n",
    "        ucb_index = self.Q_a[model] + exploration_term\n",
    "        return ucb_index\n",
    "    \n",
    "    def _get_empirical_pdf_cdf(self, a_values: List[float], current_a: float, bin_count: int = 20) -> Tuple[float, float]:\n",
    "        \"\"\"Calculates empirical PDF and CDF values for the current 'a' based on history.\"\"\"\n",
    "        if not a_values:\n",
    "            return 1.0, 0.5 \n",
    "\n",
    "        a_all = np.array(a_values + [current_a])\n",
    "        min_a, max_a = a_all.min(), a_all.max()\n",
    "        \n",
    "        if min_a == max_a:\n",
    "            return 1.0, 1.0 if current_a >= min_a else 0.0\n",
    "            \n",
    "        bins = np.linspace(min_a, max_a, bin_count + 1)\n",
    "        \n",
    "        counts, bin_edges = np.histogram(a_values, bins=bins, density=False)\n",
    "        total_samples = len(a_values)\n",
    "        bin_width = bin_edges[1] - bin_edges[0]\n",
    "        \n",
    "        current_bin_index = np.digitize(current_a, bin_edges) - 1\n",
    "        current_bin_index = np.clip(current_bin_index, 0, bin_count - 1)\n",
    "        \n",
    "        # Empirical PDF (density approximation)\n",
    "        pdf_val = (counts[current_bin_index] / total_samples) / bin_width\n",
    "        \n",
    "        # Empirical CDF\n",
    "        cdf_val = np.sum(counts[:current_bin_index + 1]) / total_samples\n",
    "        \n",
    "        pdf_val = max(pdf_val, 1e-6) # Prevent division by zero\n",
    "        \n",
    "        return pdf_val, cdf_val\n",
    "\n",
    "    def _compute_virtual_valuation(self, a: float, model: str) -> float:\n",
    "        \"\"\"Reverse Myerson Virtual Valuation: a + (CDF(a) / PDF(a))\"\"\"\n",
    "        a_history = self.a_history[model]\n",
    "        pdf_a, cdf_a = self._get_empirical_pdf_cdf(a_history, a)\n",
    "        \n",
    "        # This formula is used for the valuation based on the bid 'a'\n",
    "        virtual_valuation = a + (cdf_a / pdf_a)\n",
    "        return virtual_valuation\n",
    "\n",
    "    def select_model(self, country: str) -> str:\n",
    "        \"\"\"Selects the optimal model.\"\"\"\n",
    "        self.t += 1\n",
    "        \n",
    "        # Initial exploration: Ensure every arm is pulled once\n",
    "        for model in self.models:\n",
    "            if self.N_a[model] == 0:\n",
    "                return model\n",
    "\n",
    "        virtual_valuations: Dict[str, float] = {}\n",
    "        \n",
    "        for model in self.models:\n",
    "            # 1. Simulate the hypothetical outcome (Reward, Cost)\n",
    "            # NOTE: simulate_llm_tokens_and_performance must be defined globally\n",
    "            # reward, cost, _ = simulate_llm_tokens_and_performance(country, model) \n",
    "            reward, cost, _ = 0, 0, 0 # Placeholder for missing function\n",
    "            \n",
    "            # 2. Calculate UCB Index and Exploration Term\n",
    "            ucb_index = self._compute_ucb_index(model)\n",
    "            exploration_term = ucb_index - self.Q_a[model] \n",
    "            \n",
    "            # 3. Calculate 'a' value: a = Reward + UCB_Exploration_Term - Cost\n",
    "            a = reward + exploration_term - cost\n",
    "            \n",
    "            # 4. Compute Reverse Myerson Virtual Valuation\n",
    "            virtual_valuation = self._compute_virtual_valuation(a, model)\n",
    "            virtual_valuations[model] = virtual_valuation\n",
    "            \n",
    "        # 5. Select the model with the LOWEST Virtual Valuation\n",
    "        selected_model = min(virtual_valuations, key=virtual_valuations.get)\n",
    "        \n",
    "        return selected_model\n",
    "\n",
    "    def update_model_stats(self, selected_model: str, reward: float, cost: float):\n",
    "        \"\"\"Updates the UCB and Reverse Myerson's history for the selected model.\"\"\"\n",
    "        \n",
    "        # 1. UCB Update\n",
    "        self.N_a[selected_model] += 1\n",
    "        \n",
    "        # Update empirical mean Q_t(a) (Incremental update formula)\n",
    "        n = self.N_a[selected_model]\n",
    "        old_q = self.Q_a[selected_model]\n",
    "        new_q = old_q + (1 / n) * (reward - old_q)\n",
    "        self.Q_a[selected_model] = new_q\n",
    "        \n",
    "        # 2. Calculate and update 'a' history for Myerson\n",
    "        exploration_term = self.c_ucb * math.sqrt(math.log(self.t) / self.N_a[selected_model])\n",
    "        a = reward + exploration_term - cost\n",
    "        self.a_history[selected_model].append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07b97883-c071-482d-9df7-22b0c5714a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting LLM Selection Simulation ---\n",
      "Models: ['Model-1', 'Model-2'], UCB-C: 0.5, Rounds: 200\n",
      "Max Reward per round: 70\n",
      "\n",
      "Round 20: Model=Model-2, R=60.00, C=8.70, Net=51.30\n",
      "Round 40: Model=Model-2, R=70.00, C=9.20, Net=60.80\n",
      "Round 60: Model=Model-2, R=35.00, C=9.30, Net=25.70\n",
      "Round 80: Model=Model-2, R=70.00, C=8.80, Net=61.20\n",
      "Round 100: Model=Model-2, R=25.00, C=9.00, Net=16.00\n",
      "Round 120: Model=Model-2, R=35.00, C=8.80, Net=26.20\n",
      "Round 140: Model=Model-2, R=35.00, C=8.70, Net=26.30\n",
      "Round 160: Model=Model-2, R=60.00, C=9.10, Net=50.90\n",
      "Round 180: Model=Model-2, R=10.00, C=9.20, Net=0.80\n",
      "Round 200: Model=Model-2, R=45.00, C=9.10, Net=35.90\n",
      "\n",
      "--- Simulation Complete ---\n",
      "Total Rounds: 200\n",
      "Total Revenue: 9560.00\n",
      "Total Cost: 2183.40\n",
      "Net Profit (Revenue - Cost): 7376.60\n",
      "\n",
      "--- Model Pull Counts ---\n",
      "Model-1: 8 pulls\n",
      "Model-2: 192 pulls\n",
      "\n",
      "--- Final UCB Mean Rewards (Q_a) ---\n",
      "Model-1: 64.3750 average reward\n",
      "Model-2: 47.1094 average reward\n"
     ]
    }
   ],
   "source": [
    "def run_simulation(num_rounds: int, df: pd.DataFrame, selector: LLMBanditSelector):\n",
    "    \"\"\"Runs the multi-armed bandit simulation.\"\"\"\n",
    "    total_revenue = 0.0\n",
    "    total_cost = 0.0\n",
    "    \n",
    "    COUNTRY_LIST = df['Country'].tolist()\n",
    "\n",
    "    print(f\"--- Starting LLM Selection Simulation ---\")\n",
    "    print(f\"Models: {selector.models}, UCB-C: {selector.c_ucb}, Rounds: {num_rounds}\")\n",
    "    print(f\"Max Reward per round: {MAX_REWARD}\\n\")\n",
    "\n",
    "    for i in range(1, num_rounds + 1):\n",
    "        # 1. Choose a random country for the query\n",
    "        country = random.choice(COUNTRY_LIST)\n",
    "        \n",
    "        # 2. Select the optimal model\n",
    "        selected_model = selector.select_model(country)\n",
    "        \n",
    "        # 3. Simulate the performance (this is the actual *observation*)\n",
    "        reward, cost, tokens = simulate_llm_tokens_and_performance(country, selected_model) \n",
    "        \n",
    "        # 4. Update the selector state\n",
    "        selector.update_model_stats(selected_model, reward, cost)\n",
    "\n",
    "        total_revenue += reward\n",
    "        total_cost += cost\n",
    "        net_value = reward - cost\n",
    "        \n",
    "        if i % 20 == 0 or i == num_rounds:\n",
    "            print(f\"Round {i}: Model={selected_model}, R={reward:.2f}, C={cost:.2f}, Net={net_value:.2f}\")\n",
    "    print(\"\\n--- Simulation Complete ---\")\n",
    "    print(f\"Total Rounds: {num_rounds}\")\n",
    "    print(f\"Total Revenue: {total_revenue:.2f}\")\n",
    "    print(f\"Total Cost: {total_cost:.2f}\")\n",
    "    print(f\"Net Profit (Revenue - Cost): {total_revenue - total_cost:.2f}\")\n",
    "    \n",
    "    print(\"\\n--- Model Pull Counts ---\")\n",
    "    for model, count in selector.N_a.items():\n",
    "        print(f\"{model}: {count} pulls\")\n",
    "        \n",
    "    print(\"\\n--- Final UCB Mean Rewards (Q_a) ---\")\n",
    "    for model, q_a in selector.Q_a.items():\n",
    "        print(f\"{model}: {q_a:.4f} average reward\")\n",
    "        \n",
    "# --- Execution ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        # 1. Load the synthetic dataset\n",
    "        df_synthetic = pd.read_csv(DF_FILE_NAME)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"FATAL ERROR: Dataset not found at {DF_FILE_NAME}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # 2. Initialize the LLM Selector\n",
    "    model_names = list(MODEL_CONFIG.keys())\n",
    "    bandit_selector = LLMBanditSelector(models=model_names, c_ucb=C_UCB)\n",
    "\n",
    "    # 3. Run the simulation\n",
    "    run_simulation(SIMULATION_ROUNDS, df_synthetic, bandit_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b7bb503-a92f-4f64-a5f0-86b04292918c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "--- Starting Exclusive Simulation: Model-1 (200 Rounds) ---\n",
      "Round 50: Model=Model-1, R=70.00, C=57.60, Net=12.40\n",
      "Round 100: Model=Model-1, R=70.00, C=56.40, Net=13.60\n",
      "Round 150: Model=Model-1, R=70.00, C=57.60, Net=12.40\n",
      "Round 200: Model=Model-1, R=70.00, C=58.20, Net=11.80\n",
      "\n",
      "--- Exclusive Simulation Complete ---\n",
      "Model Used: Model-1\n",
      "Total Rounds: 200\n",
      "Total Revenue: 12230.00\n",
      "Total Cost: 11397.00\n",
      "Net Profit (Revenue - Cost): 833.00\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "--- Starting Exclusive Simulation: Model-2 (200 Rounds) ---\n",
      "Round 50: Model=Model-2, R=10.00, C=8.90, Net=1.10\n",
      "Round 100: Model=Model-2, R=70.00, C=9.20, Net=60.80\n",
      "Round 150: Model=Model-2, R=70.00, C=8.80, Net=61.20\n",
      "Round 200: Model=Model-2, R=70.00, C=9.10, Net=60.90\n",
      "\n",
      "--- Exclusive Simulation Complete ---\n",
      "Model Used: Model-2\n",
      "Total Rounds: 200\n",
      "Total Revenue: 9580.00\n",
      "Total Cost: 1798.50\n",
      "Net Profit (Revenue - Cost): 7781.50\n",
      "============================================================\n",
      "\n",
      "--- Final Comparative Profit ---\n",
      "Model-1 Exclusive Profit: 833.00\n",
      "Model-2 Exclusive Profit: 7781.50\n"
     ]
    }
   ],
   "source": [
    "# Assuming all constants (MODEL_CONFIG, REWARD_STRUCTURE, SIMULATION_ROUNDS,\n",
    "# DF_FILE_NAME, MAX_REWARD) and functions (simulate_llm_tokens_and_performance)\n",
    "# are already defined from the previous cell.\n",
    "\n",
    "def run_exclusive_model_simulation(num_rounds: int, df: pd.DataFrame, model_name: str):\n",
    "    \"\"\"\n",
    "    Runs a simulation for a fixed number of rounds using only the specified model\n",
    "    to calculate the total net profit.\n",
    "    \"\"\"\n",
    "    total_revenue = 0.0\n",
    "    total_cost = 0.0\n",
    "    \n",
    "    COUNTRY_LIST = df['Country'].tolist()\n",
    "\n",
    "    print(f\"--- Starting Exclusive Simulation: {model_name} ({num_rounds} Rounds) ---\")\n",
    "    \n",
    "    for i in range(1, num_rounds + 1):\n",
    "        # 1. Choose a random country for the query\n",
    "        country = random.choice(COUNTRY_LIST)\n",
    "        \n",
    "        # 2. Simulate the performance (This is the actual *observation*)\n",
    "        # The selected model is always the fixed model_name\n",
    "        reward, cost, tokens = simulate_llm_tokens_and_performance(country, model_name) \n",
    "        \n",
    "        total_revenue += reward\n",
    "        total_cost += cost\n",
    "        \n",
    "        if i % 50 == 0 or i == num_rounds:\n",
    "            net_value = reward - cost\n",
    "            print(f\"Round {i}: Model={model_name}, R={reward:.2f}, C={cost:.2f}, Net={net_value:.2f}\")\n",
    "\n",
    "    net_profit = total_revenue - total_cost\n",
    "    \n",
    "    print(\"\\n--- Exclusive Simulation Complete ---\")\n",
    "    print(f\"Model Used: {model_name}\")\n",
    "    print(f\"Total Rounds: {num_rounds}\")\n",
    "    print(f\"Total Revenue: {total_revenue:.2f}\")\n",
    "    print(f\"Total Cost: {total_cost:.2f}\")\n",
    "    print(f\"Net Profit (Revenue - Cost): {net_profit:.2f}\")\n",
    "    \n",
    "    return net_profit\n",
    "\n",
    "# --- Execution for Model-1 ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        # Load the synthetic dataset (assuming DF_FILE_NAME is globally accessible)\n",
    "        df_synthetic = pd.read_csv(DF_FILE_NAME)\n",
    "    except NameError:\n",
    "        print(\"Error: DF_FILE_NAME is not defined. Ensure you run the previous cell first.\")\n",
    "        sys.exit(1)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"FATAL ERROR: Dataset not found at {DF_FILE_NAME}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Run simulation using only Model-1\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    profit_model_1 = run_exclusive_model_simulation(SIMULATION_ROUNDS, df_synthetic, 'Model-1')\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Optional: Run simulation using only Model-2 for comparison\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    profit_model_2 = run_exclusive_model_simulation(SIMULATION_ROUNDS, df_synthetic, 'Model-2')\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\n--- Final Comparative Profit ---\")\n",
    "    print(f\"Model-1 Exclusive Profit: {profit_model_1:.2f}\")\n",
    "    print(f\"Model-2 Exclusive Profit: {profit_model_2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3012052e-c1f9-4d32-beec-93f17ce7b7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (My Llama Env)",
   "language": "python",
   "name": "my_llama_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
